{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec6d2a08",
   "metadata": {},
   "source": [
    "Universidad Nacional Experimental de Guayana\n",
    "\n",
    "Sistemas Distribuidos, Sección 1\n",
    "\n",
    "Bachilleres: Geruby Bermúdez Ricardo Muñoz\n",
    "\n",
    "                                            Práctica I. Parte II"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0480411",
   "metadata": {},
   "source": [
    "Para la realizacion de esta practica se necesitó tener instalado Scrapy, el cual es un framework de scraping y crawling de código abierto, escrito en Python. De esta forma, a importar scrapy podemos hacer uso de esta herramienta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca2cdfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48188016",
   "metadata": {},
   "source": [
    "Luego de hacer unas busqueda en github sobre el personaje Leslie Lamport, obtenemos el siguiente enlace de un post:\n",
    "\n",
    "    https://github.com/joyoyoyoyoyo/lamport-logical-clocks-in-a-distributed-system\n",
    "    \n",
    "De dicho enlace obtendremos los siguientes elementos:\n",
    "\n",
    "    Nombre, autor, readme, idioma, lenguajes, fecha, vistas, estrellas,fork, paquetes, releases.\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae81e84",
   "metadata": {},
   "source": [
    "<img src=\"1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935dffbe",
   "metadata": {},
   "source": [
    "<img src=\"2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe0803c",
   "metadata": {},
   "source": [
    "Scrapy nos permite crear nuestra class QuoteSpider(scrapy.Spider), que a su vez permite definir cómo se raspará el sitio web seleccionado anteriormente, incluido cómo extraer datos estructurados de dicha pagina. \n",
    "\n",
    "-name es una cadena que define el nombre de nuestra araña\n",
    "\n",
    "-En start_urls se encuentra el enlace al post en GitHub del que haremos el raspado\n",
    "\n",
    "-parse es el método como función de devolución de llamada para las solicitudes.\n",
    "\n",
    "-resonse es la respuesta a los requerimientos sobre el sitio web que solicitadmos en nuestra araña \n",
    "\n",
    "-Con yield nos muestra el diccionario que contienen los datos extraídos de la página"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74224754",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuoteSpider(scrapy.Spider):\n",
    "    name = 'gh'\n",
    "    start_urls = [\n",
    "        'https://github.com/joyoyoyoyoyo/lamport-logical-clocks-in-a-distributed-system/',\n",
    "    ]\n",
    "\n",
    "    def parse(self, response):\n",
    "        autor = response.xpath('//div/span/a/text()').extract_first()\n",
    "            \n",
    "        yield{'autor': autor}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b86a56",
   "metadata": {},
   "source": [
    "Para especificar la ruta de donde se deben obtener cada dato que requerimos del post en github se utilizo xpath junto con la inspeccion de elementos de la misma paguina web."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584222c7",
   "metadata": {},
   "source": [
    "<img src=\"3.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547849e6",
   "metadata": {},
   "source": [
    "Especificando la ruta con xpath quedaria de la siguiente manera:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd168c53",
   "metadata": {},
   "source": [
    "<img src=\"4.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ed4ca7",
   "metadata": {},
   "source": [
    "Para ingresar dicha ruta en nuestro proyecto, se escribiria la siguiente linea: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d763e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "autor = response.xpath('//div/span/a/text()').extract_first()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef092a5",
   "metadata": {},
   "source": [
    "Se realiza el mismo proceso para los demas elementos que queremos obtener de la paguina e igresamos cada ruta con la sintaxis que corresponde en nuestro proyecto, quedando nuestro codigo de la siguiente manera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7733fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "\n",
    "class QuoteSpider(scrapy.Spider):\n",
    "    name = 'gh'\n",
    "    start_urls = [\n",
    "        'https://github.com/joyoyoyoyoyo/lamport-logical-clocks-in-a-distributed-system/',\n",
    "    ]\n",
    "\n",
    "    def parse(self, response):\n",
    "        autor = response.xpath('//div/span/a/text()').extract_first()\n",
    "        titulo = response.xpath('//div/strong/a/text()').extract_first()\n",
    "        titulocarpeta1 = response.xpath('//div[2]/span/a/text()').extract_first()\n",
    "        tituloreadme = response.xpath('//div/h2/a/text()').extract_first()\n",
    "        infreadme = response.xpath('//div/div/pre/text()').extract_first()\n",
    "        star = response.xpath('//div[@class=\"mt-2\"]/a/strong/text()').extract_first()\n",
    "        view = response.xpath('//div[@class=\"mt-2\"][3]/a/strong/text()').extract_first()\n",
    "        forks = response.xpath('//div[@class=\"mt-2\"][4]/a/strong/text()').extract_first()\n",
    "        releases = response.xpath('//div[@class=\"text-small color-fg-muted\"]/text()').extract_first()\n",
    "        fecha = response.xpath('//relative-time[@class=\"no-wrap\"]/text()').extract_first()\n",
    "        tag1 = response.xpath('//a[@class=\"topic-tag topic-tag-link\"]/text()').extract_first()\n",
    "        tag2 = response.xpath('//div[@class=\"f6\"]/a[2]/text()').extract_first()\n",
    "            \n",
    "\n",
    "        yield{'autor': autor, 'titulo': titulo, 'titulo carpeta 1': titulocarpeta1, 'README.txt': tituloreadme,\n",
    "               'contenido README': infreadme, 'Star': star, 'view': view, 'forks': forks, 'releases': releases,\n",
    "               'fecha': fecha, 'Etiqueta 1': tag1, 'Etiqueta 2': tag2\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed683a2d",
   "metadata": {},
   "source": [
    "Al ejecutarlo en Visual Studio Code, con el comando:\n",
    "\n",
    "scrapy crawl gh -o pgh.csv\n",
    "\n",
    "Obtendremos los datos extraidos en un archivo csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
